{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CECS456Final.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNA+kgnBm756QfDdJ7FCGK3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidr27/456Project/blob/main/CECS456Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kG15oUVz_xC"
      },
      "outputs": [],
      "source": [
        "#importing libraries \n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "from numpy import asarray\n",
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download folders from kaggle\n",
        "! mkdir .kaggle\n",
        "! mv .kaggle /root/.kaggle\n",
        "file = open('/root/.kaggle/kaggle.json', 'w')\n",
        "# get key from your kaggle account\n",
        "file.write('{\"username\":\"\",\"key\":\"\"}')\n",
        "file.close()\n",
        "! kaggle datasets download -d alessiocorrado99/animals10"
      ],
      "metadata": {
        "id": "irxM2p-F0wUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip folder\n",
        "!unzip animals10.zip"
      ],
      "metadata": {
        "id": "yOuhW1Zq1DXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = 'raw-img/'\n",
        "\n",
        "img_height = 227\n",
        "img_width = 227\n",
        "#batch size 32 recommended \n",
        "batch_size = 32\n",
        "#obtains the training set a validation split of 0.2 is set\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    subset=\"training\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    class_names=['cane', 'cavallo', 'elefante', 'farfalla', 'gallina', 'gatto', 'mucca', 'pecora', 'ragno', 'scoiattolo'],\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(img_height, img_width),\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    validation_split=0.2,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False,\n",
        ")\n",
        "\n",
        "#obtains the validation set a validation split of 0.2 is set\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  dataset_path,\n",
        "  subset=\"validation\",\n",
        "  labels=\"inferred\",\n",
        "  label_mode=\"int\",\n",
        "  class_names=['cane', 'cavallo', 'elefante', 'farfalla', 'gallina', 'gatto', 'mucca', 'pecora', 'ragno', 'scoiattolo'],\n",
        "  batch_size=batch_size,\n",
        "  image_size=(img_height, img_width),\n",
        "  shuffle=True,\n",
        "  seed=123,\n",
        "  validation_split=0.2,\n",
        "  interpolation=\"bilinear\",\n",
        "  follow_links=False,\n",
        "  crop_to_aspect_ratio=False,\n",
        ")"
      ],
      "metadata": {
        "id": "p9Igg_291GLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#standarize the data values in the model by applying rescaling \n",
        "\n",
        "#Implementing AlexNet \n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D,BatchNormalization, Rescaling\n",
        "#Create a sequential model \n",
        "model = Sequential()\n",
        "model.add(Rescaling(1./255, input_shape=(227, 227, 3)))\n",
        "model.add(Conv2D(filters=96, input_shape=(227, 227, 3),kernel_size=(11, 11),strides=(4,4),padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Pooling \n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Dense Layer\n",
        "model.add(Dense(1000))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "DoWS_cwS5VK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compile the model \n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "fSxoFcwe8QTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#modify number of epochs accordingly. AlexNet showed no improvement after 20 epochs but was tested with 50. \n",
        "epochs = 50\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs,\n",
        "  verbose='auto'\n",
        ")"
      ],
      "metadata": {
        "id": "sP_tzGlS8TW7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}